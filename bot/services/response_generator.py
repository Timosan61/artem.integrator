"""
–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç–≤–µ—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º AI

–û—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
"""

import logging
import json
from typing import List, Dict, Any, Optional
from datetime import datetime

import openai
from anthropic import AsyncAnthropic

from ..core.interfaces import IResponseGenerator, Message, Response, ServiceError
from ..core.utils import TextUtils, RetryUtils, FileUtils
from ..core.decorators import measure_time, handle_errors, ensure_service_enabled
from ..core.config import config


logger = logging.getLogger(__name__)


class OpenAIResponseGenerator(IResponseGenerator):
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ OpenAI"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞"""
        self.enabled = config.openai.enabled
        self.model = config.openai.model
        self.instructions = self._load_instructions()
        
        if self.enabled:
            logger.info(f"‚úÖ OpenAI Response Generator –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–º–æ–¥–µ–ª—å: {self.model})")
        else:
            logger.warning("‚ö†Ô∏è OpenAI Response Generator –æ—Ç–∫–ª—é—á–µ–Ω - –Ω–µ—Ç API –∫–ª—é—á–∞")
    
    @measure_time
    @ensure_service_enabled('openai')
    @RetryUtils.retry(max_attempts=3, delay=1.0, exceptions=(openai.OpenAIError,))
    async def generate(self, message: Message, context: List[Dict[str, Any]]) -> Response:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ"""
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            system_prompt = self._prepare_system_prompt(message.user)
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è API
            messages = [{"role": "system", "content": system_prompt}]
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
            for ctx_msg in context:
                messages.append({
                    "role": ctx_msg.get("role", "user"),
                    "content": ctx_msg.get("content", "")
                })
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            messages.append({
                "role": "user",
                "content": message.text or f"[{message.type.value}]"
            })
            
            # –í—ã–∑—ã–≤–∞–µ–º OpenAI API
            client = openai.AsyncOpenAI(api_key=config.openai.api_key)
            response = await client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.7,
                max_tokens=1000,
                user=str(message.user.id)
            )
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç
            ai_response = response.choices[0].message.content
            
            # –û–±—Ä–µ–∑–∞–µ–º –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π
            ai_response = TextUtils.truncate(ai_response, config.max_message_length)
            
            logger.debug(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –æ—Ç–≤–µ—Ç –¥–ª—è user {message.user.id}")
            
            return Response(
                text=ai_response,
                metadata={
                    "model": self.model,
                    "tokens_used": response.usage.total_tokens if response.usage else 0
                }
            )
            
        except openai.RateLimitError as e:
            logger.error(f"‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç OpenAI API: {e}")
            raise ServiceError("–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
        except openai.OpenAIError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ OpenAI API: {e}")
            raise ServiceError(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
        except Exception as e:
            logger.error(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
            raise ServiceError(f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞: {e}")
    
    async def is_available(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞"""
        return self.enabled
    
    def _prepare_system_prompt(self, user) -> str:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç"""
        current_date = datetime.now().strftime("%Y-%m-%d")
        
        prompt = f"""{self.instructions.get('base_prompt', '')}

–¢–µ–∫—É—â–∞—è –¥–∞—Ç–∞: {current_date}
–ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user.full_name}
–Ø–∑—ã–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user.language_code or 'ru'}

{self.instructions.get('behavior_rules', '')}"""
        
        return prompt
    
    def _load_instructions(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏–∑ —Ñ–∞–π–ª–∞"""
        instruction_file = config.data_dir / 'instruction.json'
        default_instructions = {
            "base_prompt": "–¢—ã - AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –∏–º–µ–Ω–∏ –ê—Ä—Ç—ë–º.",
            "behavior_rules": "–ë—É–¥—å –≤–µ–∂–ª–∏–≤—ã–º –∏ –ø–æ–ª–µ–∑–Ω—ã–º."
        }
        
        instructions = FileUtils.safe_json_load(instruction_file, default_instructions)
        logger.info(f"üìù –ó–∞–≥—Ä—É–∂–µ–Ω—ã –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏–∑ {instruction_file}")
        
        return instructions


class AnthropicResponseGenerator(IResponseGenerator):
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ Anthropic Claude"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞"""
        self.enabled = config.anthropic.enabled
        self.model = config.anthropic.model
        self.client = None
        self.instructions = self._load_instructions()
        
        if self.enabled:
            self.client = AsyncAnthropic(api_key=config.anthropic.api_key)
            logger.info(f"‚úÖ Anthropic Response Generator –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–º–æ–¥–µ–ª—å: {self.model})")
        else:
            logger.warning("‚ö†Ô∏è Anthropic Response Generator –æ—Ç–∫–ª—é—á–µ–Ω - –Ω–µ—Ç API –∫–ª—é—á–∞")
    
    @measure_time
    @ensure_service_enabled('anthropic')
    @RetryUtils.retry(max_attempts=3, delay=1.0)
    async def generate(self, message: Message, context: List[Dict[str, Any]]) -> Response:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ"""
        if not self.client:
            raise ServiceError("Anthropic –∫–ª–∏–µ–Ω—Ç –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            system_prompt = self._prepare_system_prompt(message.user)
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è API
            messages = []
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
            for ctx_msg in context:
                messages.append({
                    "role": ctx_msg.get("role", "user"),
                    "content": ctx_msg.get("content", "")
                })
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            messages.append({
                "role": "user",
                "content": message.text or f"[{message.type.value}]"
            })
            
            # –í—ã–∑—ã–≤–∞–µ–º Claude API
            response = await self.client.messages.create(
                model=self.model,
                max_tokens=1024,
                system=system_prompt,
                messages=messages,
                metadata={"user_id": str(message.user.id)}
            )
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç
            ai_response = response.content[0].text
            
            # –û–±—Ä–µ–∑–∞–µ–º –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π
            ai_response = TextUtils.truncate(ai_response, config.max_message_length)
            
            logger.debug(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –æ—Ç–≤–µ—Ç Claude –¥–ª—è user {message.user.id}")
            
            return Response(
                text=ai_response,
                metadata={
                    "model": self.model,
                    "tokens_used": response.usage.input_tokens + response.usage.output_tokens
                }
            )
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ Anthropic API: {e}")
            raise ServiceError(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
    
    async def is_available(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞"""
        return self.enabled and self.client is not None
    
    def _prepare_system_prompt(self, user) -> str:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç"""
        current_date = datetime.now().strftime("%Y-%m-%d")
        
        prompt = f"""{self.instructions.get('base_prompt', '')}

–¢–µ–∫—É—â–∞—è –¥–∞—Ç–∞: {current_date}
–ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user.full_name}
–Ø–∑—ã–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user.language_code or 'ru'}

{self.instructions.get('behavior_rules', '')}"""
        
        return prompt
    
    def _load_instructions(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏–∑ —Ñ–∞–π–ª–∞"""
        instruction_file = config.data_dir / 'instruction.json'
        default_instructions = {
            "base_prompt": "–¢—ã - AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –∏–º–µ–Ω–∏ –ê—Ä—Ç—ë–º.",
            "behavior_rules": "–ë—É–¥—å –≤–µ–∂–ª–∏–≤—ã–º –∏ –ø–æ–ª–µ–∑–Ω—ã–º."
        }
        
        instructions = FileUtils.safe_json_load(instruction_file, default_instructions)
        logger.info(f"üìù –ó–∞–≥—Ä—É–∂–µ–Ω—ã –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏–∑ {instruction_file}")
        
        return instructions


class HybridResponseGenerator(IResponseGenerator):
    """–ì–∏–±—Ä–∏–¥–Ω—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞"""
        self.generators = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã
        if config.openai.enabled:
            self.generators.append(OpenAIResponseGenerator())
        
        if config.anthropic.enabled:
            self.generators.append(AnthropicResponseGenerator())
        
        if not self.generators:
            logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤ –æ—Ç–≤–µ—Ç–æ–≤")
    
    async def generate(self, message: Message, context: List[Dict[str, Any]]) -> Response:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É—è –ø–µ—Ä–≤—ã–π –¥–æ—Å—Ç—É–ø–Ω—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä"""
        last_error = None
        
        for generator in self.generators:
            try:
                if await generator.is_available():
                    return await generator.generate(message, context)
            except Exception as e:
                logger.warning(f"–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä {type(generator).__name__} –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å: {e}")
                last_error = e
                continue
        
        if last_error:
            raise last_error
        else:
            raise ServiceError("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤ –æ—Ç–≤–µ—Ç–æ–≤")
    
    async def is_available(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–≥–æ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞"""
        for generator in self.generators:
            if await generator.is_available():
                return True
        return False


class SimpleResponseGenerator(IResponseGenerator):
    """–ü—Ä–æ—Å—Ç–æ–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç–≤–µ—Ç–æ–≤ –±–µ–∑ AI (fallback)"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞"""
        self.responses = {
            "greeting": [
                "–ü—Ä–∏–≤–µ—Ç! –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?",
                "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –Ø –≥–æ—Ç–æ–≤ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–∞—à–∏ –≤–æ–ø—Ä–æ—Å—ã.",
                "–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å! –ö–∞–∫ —è –º–æ–≥—É –≤–∞–º –ø–æ–º–æ—á—å?"
            ],
            "farewell": [
                "–î–æ —Å–≤–∏–¥–∞–Ω–∏—è! –ë—ã–ª —Ä–∞–¥ –ø–æ–º–æ—á—å.",
                "–£–¥–∞—á–∏! –û–±—Ä–∞—â–∞–π—Ç–µ—Å—å, –µ—Å–ª–∏ –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è –ø–æ–º–æ—â—å.",
                "–í—Å–µ–≥–æ –¥–æ–±—Ä–æ–≥–æ! –ó–∞—Ö–æ–¥–∏—Ç–µ –µ—â—ë."
            ],
            "help": [
                "–Ø –º–æ–≥—É –ø–æ–º–æ—á—å –≤–∞–º —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏. –ü—Ä–æ—Å—Ç–æ —Å–ø—Ä–æ—Å–∏—Ç–µ!",
                "–í–æ—Ç —á—Ç–æ —è —É–º–µ—é:\n- –û—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã\n- –ü–æ–º–æ–≥–∞—Ç—å —Å –∑–∞–¥–∞—á–∞–º–∏\n- –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é"
            ],
            "gratitude": [
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞! –†–∞–¥ –±—ã–ª –ø–æ–º–æ—á—å.",
                "–ù–µ –∑–∞ —á—Ç–æ! –û–±—Ä–∞—â–∞–π—Ç–µ—Å—å –µ—â—ë.",
                "–í—Å–µ–≥–¥–∞ —Ä–∞–¥ –ø–æ–º–æ—á—å!"
            ],
            "default": [
                "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ —Å–æ–≤—Å–µ–º –ø–æ–Ω—è–ª –≤–∞—à –≤–æ–ø—Ä–æ—Å. –ú–æ–∂–µ—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å?",
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø–æ-–¥—Ä—É–≥–æ–º—É.",
                "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ –º–æ–≥—É –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–∞—à –∑–∞–ø—Ä–æ—Å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑."
            ]
        }
    
    async def generate(self, message: Message, context: List[Dict[str, Any]]) -> Response:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ—Å—Ç–æ–π –æ—Ç–≤–µ—Ç"""
        # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –≤—ã–±–æ—Ä–∞ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ intent
        # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç
        import random
        
        response_text = random.choice(self.responses["default"])
        
        return Response(
            text=response_text,
            metadata={"generator": "simple"}
        )
    
    async def is_available(self) -> bool:
        """–í—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–µ–Ω"""
        return True